{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, roc_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score, roc_curve\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"./data.pkl\")\n",
    "\n",
    "# split data into X and y\n",
    "X = data.loc[:, data.columns != 'bot']\n",
    "Y = data.loc[:, data.columns == 'bot'].to_numpy()\n",
    "\n",
    "# split data into train and test sets\n",
    "seed = 10\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for this algortihm has to be either 1 or -1\n",
    "y_train = np.where(y_train < 0.5, -1, 1)\n",
    "y_test = np.where(y_test < 0.5, -1, 1)\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom implementation of AdaBoost algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ourAdaboostClassifier:\n",
    "    def __init__(self, x=None,y=None, n_iterations = 100):\n",
    "        self.number_iterations = n_iterations\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        number_samples = np.shape(X_train)[0]\n",
    "        weights = np.ones(number_samples)/number_samples\n",
    "        \n",
    "        # There will be as many weak learners as iterations\n",
    "        self.weak_learners = np.zeros(shape=self.number_iterations, dtype=object)\n",
    "        self.significance_vec = np.zeros(shape=self.number_iterations)\n",
    "        error_vec = []\n",
    "        accuracy_vec = []\n",
    "        \n",
    "        for iterations in range(self.number_iterations):\n",
    "            current_weights = weights\n",
    "\n",
    "            weak_learner = DecisionTreeClassifier(max_depth=1, max_leaf_nodes=2)\n",
    "            weak_learner_model = weak_learner.fit(X_train, y_train, sample_weight=current_weights)\n",
    "\n",
    "            # The new weak learner model is saved\n",
    "            self.weak_learners[iterations] = weak_learner_model\n",
    "            weak_learner_pred = weak_learner_model.predict(X_train)\n",
    "\n",
    "            error = 0\n",
    "            incorrect_pred = 0\n",
    "            correct_pred = 0\n",
    "            for item_index in range(number_samples):\n",
    "                if weak_learner_pred[item_index] != y_train[item_index]:\n",
    "                    incorrect_pred = incorrect_pred + 1\n",
    "                    error = error + current_weights[item_index]\n",
    "                else: \n",
    "                    correct_pred = correct_pred + 1 \n",
    "\n",
    "            # Save error for plotting    \n",
    "            # error_vec.append(error)\n",
    "\n",
    "            # Significance of the weak learner model is calculated and saved\n",
    "            significance = 0.5*np.log((1-error)/error) \n",
    "            self.significance_vec[iterations] = significance\n",
    "\n",
    "            # Update weights for each sample\n",
    "            for item_index in range(number_samples):\n",
    "                if weak_learner_pred[item_index] != y_train[item_index]:\n",
    "                    weights[item_index] = np.multiply(current_weights[item_index],np.exp(significance))\n",
    "                else:\n",
    "                    weights[item_index] = current_weights[item_index]*np.exp(-significance)\n",
    "\n",
    "            # Normalize weights\n",
    "            weights /= weights.sum()\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        model_preds = np.array([model.predict(X_test) for model in self.weak_learners])\n",
    "        y_test_pred = np.sign(np.dot(self.significance_vec, model_preds))\n",
    "        return y_test_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaCost:\n",
    "    \"\"\"This is the implementation of the AdaCost Classifier. In this algorithm, \n",
    "    the weight update is modified by adding a cost adjustment function φ. \n",
    "    This function, for an instance with a higher cost factor increases its weight \n",
    "    “more” if the instance is misclassified, but decreases its weight “less” otherwise.\n",
    "    \n",
    "    This implementation uses the function φ = +/-0.5*cost + 0.5\n",
    "    \n",
    "    Requires:\n",
    "        X_train: Training features. Size N x D\n",
    "        y_train: Training labels. Size N x 1\n",
    "        cost: cost used to update weight via the adjustment function\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x=None,y=None, n_iterations = 100):\n",
    "        self.number_iterations = n_iterations\n",
    "        \n",
    "    def fit(self,X_train,y_train, cost):\n",
    "        # Initialize weights\n",
    "        number_samples = len(X_train)\n",
    "        weights = np.ones(number_samples)/number_samples\n",
    "        \n",
    "        # Define adjustment function φ (called beta)\n",
    "        beta = 0.5*np.ones(number_samples)\n",
    "        beta[np.where(y_train==1)[0]] += cost*0.5\n",
    "        beta[np.where(y_train==-1)[0]] -= cost*0.5\n",
    "        \n",
    "        # Define vectors to store weak predictors and significances of each iteration\n",
    "        self.weak_learners = np.zeros(shape=self.number_iterations, dtype=object)\n",
    "        self.significance_vec = np.zeros(shape=self.number_iterations)\n",
    "        \n",
    "        for it in range(self.number_iterations):\n",
    "            current_weights = weights\n",
    "            \n",
    "            # Create and save week learner for this iteration\n",
    "            weak_learner_model = DecisionTreeClassifier(max_depth=1, \n",
    "                                 max_leaf_nodes=2).fit(X_train, y_train, sample_weight=current_weights)\n",
    "            self.weak_learners[it] = weak_learner_model\n",
    "            weak_learner_pred = weak_learner_model.predict(X_train)\n",
    "            \n",
    "            # Calculate r\n",
    "            u = np.multiply(np.multiply(weak_learner_pred, y_train),beta)\n",
    "            r = np.sum(np.multiply(weights,u))\n",
    "            \n",
    "            # Calculate and store significance of this iteration\n",
    "            significance = 0.5 * np.log((1+r)/(1-r))\n",
    "            self.significance_vec[it] = significance\n",
    "            \n",
    "            # Update weights for next iteration\n",
    "            weights = np.multiply(weights,np.exp(-significance * u))\n",
    "            weights /= weights.sum()    \n",
    "            \n",
    "            # Round Debugging\n",
    "            #print('Round %d' % (it))\n",
    "            #print(u)\n",
    "            #print(r)\n",
    "            #print(significance)\n",
    "            #print(weights)\n",
    "            \n",
    "            #input()\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        model_preds = np.array([model.predict(X_test) for model in self.weak_learners])\n",
    "        y_test_pred = np.sign(np.dot(self.significance_vec, model_preds))\n",
    "        return y_test_pred.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7b248b3ac11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#ourpredictions = ourClassifier.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mourAdaCostpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaCostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy with default Adaboost: %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy with our Adaboost:     %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mourpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy with AdaCost:          %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mourAdaCostpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "#classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=100)\n",
    "#classifier.fit(X_train, y_train)\n",
    "#predictions = classifier.predict(X_test)\n",
    "\n",
    "#ourClassifier = ourAdaboostClassifier()\n",
    "AdaCostClassifier = AdaCost()\n",
    "\n",
    "#ourClassifier.fit(X_train, y_train)\n",
    "AdaCostClassifier.fit(X_train, y_train,cost = 0.5)\n",
    "\n",
    "#ourpredictions = ourClassifier.predict(X_test)\n",
    "ourAdaCostpred = AdaCostClassifier.predict(X_test)\n",
    "print('Accuracy with default Adaboost: %.4f' % (len(np.where(y_test==predictions)[0])/len(y_test)))\n",
    "print('Accuracy with our Adaboost:     %.4f' % (len(np.where(y_test==ourpredictions)[0])/len(y_test)))\n",
    "print('Accuracy with AdaCost:          %.4f' % (len(np.where(y_test==ourAdaCostpred)[0])/len(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finding the best cost fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ourCostClassifier = AdaCost()\n",
    "accuracy = []\n",
    "costs = np.linspace(-0.5,0.5,11)\n",
    "for c in tqdm(costs):\n",
    "    ourCostClassifier.fit(X_train, y_train,cost = c)\n",
    "    ourCostpredictions = ourCostClassifier.predict(X_test)\n",
    "    accuracy.append(len(np.where(y_test==ourCostpredictions)[0])/len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy vs. Cost\n",
    "base_acc = (len(np.where(y_test==ourpredictions)[0])/len(y_test))\n",
    "\n",
    "plt.figure()\n",
    "ax1 = plt.subplot(111)\n",
    "plt.grid(True,which='major',linewidth=0.5)\n",
    "plt.grid(True,which='minor',linewidth=0.1)\n",
    "plt.plot(costs, accuracy,'-o')\n",
    "plt.xlabel('Cost')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "plt.plot(costs,(np.array(accuracy)-base_acc)/base_acc*100,'o',color='tab:red')\n",
    "ax2.set_ylabel('Accuracy increase (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iterations = 100\n",
    "\n",
    "number_samples = np.shape(X_train)[0]\n",
    "\n",
    "weights = np.ones(number_samples)/number_samples\n",
    "\n",
    "# There will be as many weak learners as iterations\n",
    "weak_learners = np.zeros(shape=number_iterations, dtype=object)\n",
    "\n",
    "significance_vec = np.zeros(shape=number_iterations)\n",
    "\n",
    "error_vec = []\n",
    "accuracy_vec = []\n",
    "\n",
    "for iterations in range(number_iterations):\n",
    "    \n",
    "    current_weights = weights\n",
    "    \n",
    "    weak_learner = DecisionTreeClassifier(max_depth=1, max_leaf_nodes=2)\n",
    "    weak_learner_model = weak_learner.fit(X_train, y_train, sample_weight=current_weights)\n",
    "    \n",
    "    \n",
    "    # The new weak learner model is saved\n",
    "    weak_learners[iterations] = weak_learner_model\n",
    "    \n",
    "    weak_learner_pred = weak_learner_model.predict(X_train)\n",
    "    \n",
    "    error = 0\n",
    "    incorrect_pred = 0\n",
    "    correct_pred = 0\n",
    "    \n",
    "    for item_index in range(number_samples):\n",
    "\n",
    "        if weak_learner_pred[item_index] != y_train[item_index]:\n",
    "            incorrect_pred = incorrect_pred + 1\n",
    "            error = error + current_weights[item_index]\n",
    "        else: \n",
    "            correct_pred = correct_pred + 1 \n",
    "            \n",
    "    # Save error for plotting    \n",
    "    error_vec.append(error)\n",
    "    \n",
    "    # Significance of the weak learner model is calculated and saved\n",
    "   \n",
    "    significance = 0.5*np.log((1-error)/error) \n",
    "        \n",
    "    significance_vec[iterations] = significance\n",
    "\n",
    "    #########################\n",
    "    \n",
    "    # Update weights for each sample\n",
    "    \n",
    "    for item_index in range(number_samples):\n",
    "        if weak_learner_pred[item_index] != y_train[item_index]:\n",
    "\n",
    "            weights[item_index] = np.multiply(current_weights[item_index],np.exp(significance))\n",
    "\n",
    "        else:\n",
    "            weights[item_index] = current_weights[item_index]*np.exp(-significance)\n",
    "     \n",
    "    # Alternative\n",
    "    # weights = current_weights * np.exp(-significance*  y_train * weak_learner_pred)\n",
    "    \n",
    "\n",
    "    #########################\n",
    "    \n",
    "    # Normalize weights\n",
    "    \n",
    "    weights /= weights.sum()\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=100)\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_svm = AdaBoostClassifier(SVC(gamma=1/2/(50**2)),n_estimators=100,algorithm='SAMME')\n",
    "classifier_svm.fit(X_train, y_train)\n",
    "predictions = classifier_svm.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8572309589885908\n"
     ]
    }
   ],
   "source": [
    "print(len(np.where(predictions==y_test)[0])/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(error_vec)\n",
    "#plt.plot(significance_vec)\n",
    "plt.plot(classifier.estimator_errors_)\n",
    "plt.plot(classifier_svm.estimator_errors_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction of each weak learner \n",
    "model_preds = np.array([model.predict(X_test) for model in weak_learners])\n",
    "y_test_pred = np.sign(np.dot(significance_vec, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy \n",
    "\n",
    "correct_pred = 0\n",
    "\n",
    "for item_index in range(np.shape(y_test_pred)[0]):\n",
    "\n",
    "        if y_test_pred[item_index] == y_test[item_index]:\n",
    "\n",
    "            correct_pred = correct_pred + 1 \n",
    "            \n",
    "print(\"Accuracy custom implementation = \" + str(correct_pred/np.shape(y_test_pred)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score = f1_score(y_test, y_test_pred.astype(int), average='weighted')\n",
    "print(\"F1 Score Adaboost: \" + str(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn implementation of AdaBoost Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=100)\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy \n",
    "\n",
    "correct_pred = 0\n",
    "\n",
    "for item_index in range(np.shape(predictions)[0]):\n",
    "\n",
    "        if predictions[item_index] == y_test[item_index]:\n",
    "\n",
    "            correct_pred = correct_pred + 1 \n",
    "            \n",
    "print(\"Accuracy sklearn implementation = \" + str(correct_pred/np.shape(y_test_pred)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score = f1_score(y_test, predictions, average='weighted')\n",
    "print(\"F1 Score Adaboost: \" + str(f1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
